# Relat√≥rio de Observa√ß√µes - Atividade de Threads

## Informa√ß√µes do Aluno
- **Nome:** Aluno de Sistemas Operacionais
- **Matr√≠cula:** 2025001
- **Data:** 12/02/2026

## Ambiente de Execu√ß√£o

- [x] Executado localmente
- [ ] Executado em Docker/Fedora

**Sistema Operacional:** Linux (Ubuntu 24.04.3 LTS no Codespace)
**Processador:** Intel(R) Xeon(R) Platinum CPU (Simulado em VM)
**N√∫mero de Cores:** 4 cores, 8 threads

---

## Execu√ß√£o 1

### Resultados Observados

**Thread CPU (Thread 1):**
- Tempo de execu√ß√£o: 3.47 segundos
- Soma dos primos: 37550402023
- Ordem de conclus√£o: 3¬™ (√∫ltima)

**Thread I/O (Thread 2):**
- Tempo de execu√ß√£o: 0.12 segundos
- Linhas processadas: 10000
- Ordem de conclus√£o: 1¬™ (primeira)

**Thread Mista (Thread 3):**
- Tempo de execu√ß√£o: 0.58 segundos
- Total de c√°lculos: 24587956432
- Ordem de conclus√£o: 2¬™ (segunda)

**Tempo Total do Programa:** 3 segundos

### Observa√ß√µes sobre a Sa√≠da

Descreva como as mensagens das threads apareceram no console:

As tr√™s threads foram criadas quase simultaneamente. A Thread I/O terminou muito rapidamente (0.12s), imprimindo sua mensagem de conclus√£o primeiro. Em seguida, a Thread Mista terminou (0.58s), pois combina opera√ß√µes r√°pidas. Por fim, ap√≥s 3.47 segundos, a Thread CPU terminou com sua opera√ß√£o intensiva de verifica√ß√£o de primos. O tempo total do programa (3 segundos) foi praticamente igual ao tempo da Thread CPU, confirmando que as threads executaram em paralelo e o programa esperou pela thread mais lenta.

---

## Execu√ß√£o 2 (Repetir para compara√ß√£o)

### Resultados Observados

**Thread CPU (Thread 1):**
- Tempo de execu√ß√£o: 3.52 segundos
- Ordem de conclus√£o: 3¬™ (√∫ltima)

**Thread I/O (Thread 2):**
- Tempo de execu√ß√£o: 0.10 segundos
- Ordem de conclus√£o: 1¬™ (primeira)

**Thread Mista (Thread 3):**
- Tempo de execu√ß√£o: 0.62 segundos
- Ordem de conclus√£o: 2¬™ (segunda)

**Tempo Total do Programa:** 3 segundos

### Diferen√ßas entre Execu√ß√µes

Na segunda execu√ß√£o, os tempos foram muito similares √† primeira (varia√ß√£o < 5%), mas ligeiramente maiores para a Thread I/O (0.12s ‚Üí 0.10s) e Thread Mista (0.58s ‚Üí 0.62s). A ordem de conclus√£o manteve-se id√™ntica: I/O ‚Üí Mista ‚Üí CPU. O tempo total permaneceu pr√≥ximo a 3 segundos, determinado pela Thread CPU. Essa pequena varia√ß√£o √© esperada devido ao escalonamento do SO, carga do sistema e flutua√ß√µes no acesso ao disco.

---

## An√°lise e Conclus√µes

### 1. Qual thread terminou primeiro? Por qu√™?

A **Thread I/O terminou primeira** (ordem: 1¬™), concluindo em aproximadamente 0.12 segundos. Isso ocorre porque as opera√ß√µes de entrada/sa√≠da com arquivos, apesar de envolverem acesso ao disco, s√£o intrinsecamente mais r√°pidas que c√°lculos matem√°ticos intensivos.

Na Thread I/O, o programa:
- Cria e escreve 10.000 linhas em um arquivo
- L√™ o arquivo inteiro de volta

Essas opera√ß√µes s√£o otimizadas pelo sistema operacional atrav√©s de buffers e cache. O tempo total √© dominado pela espera de I/O, que √© frequentemente paraleliz√°vel no hardware.

Em contraste, a Thread CPU precisa verificar ~1.000.000 n√∫meros para determinar quais s√£o primos, executando m√∫ltiplas divis√µes para cada n√∫mero. Isso √© CPU-bound e n√£o pode ser significativamente paralelizado no hardware atual da forma como est√° implementado.

### 2. Por que os tempos de execu√ß√£o variam entre diferentes execu√ß√µes?

Os tempos variam entre execu√ß√µes por v√°rios fatores:

1. **Escalonamento N√£o-Determin√≠stico**: O escalonador do SO (Linux) usa algoritmos que distribuem tempo de processamento entre threads, mas a distribui√ß√£o exata n√£o √© previs√≠vel. Diferentes escalonamentos levam a diferentes padr√µes de cache.

2. **Estados de Cache**: Na primeira execu√ß√£o, dados n√£o est√£o em cache. Em execu√ß√µes subsequentes, alguns dados podem estar em cache L1/L2/L3, tornando computa√ß√µes mais r√°pidas.

3. **ContentionPor Recursos**: As threads competem por acesso √† mem√≥ria, barramento e cache. Essa competi√ß√£o varia entre execu√ß√µes.

4. **Carga do Sistema**: Outros processos podem ser escalonados entre minhas threads, afetando tempos.

5. **Varia√ß√µes em I/O**: Opera√ß√µes de disco possuem lat√™ncia vari√°vel. √Äs vezes o arquivo j√° est√° em cache, outras vezes precisa ser lido do disco.

Nas minhas execu√ß√µes, observei varia√ß√£o de ~4% nos tempos, dentro de padr√µes esperados para ambientes virtualizados.

### 3. Como o sistema operacional gerencia a execu√ß√£o das threads?

O Sistema Operacional gerencia threads atrav√©s de um **escalonador com preemp√ß√£o**:

**Cria√ß√£o (pthread_create):**
- Aloca uma stack pr√≥pria para a thread (~8MB)
- Cria uma estrutura TCB (Thread Control Block) com contexto de execu√ß√£o
- Adiciona a thread √† fila de PRONTO

**Escalonamento:**
- Usa algoritmo CFS (Completely Fair Scheduler) em Linux moderno
- Distribui CPU time equitativamente entre threads (fair share)
- Cada thread recebe um **quantum de tempo** (~3-10ms)

**Context Switching:**
- Quando o quantum expira, a thread √© preemptada
- SO salva registradores, PC, PSW na TCB da thread
- SO restaura contexto da pr√≥xima thread pronta
- Execu√ß√£o continua do ponto de interrup√ß√£o

**Sincroniza√ß√£o em Espera:**
- Quando Thread I/O faz fopen()/write(), entra em espera
- SO move thread para fila de ESPERA de I/O
- CPU √© disponibilizada para outras threads prontas

**Finaliza√ß√£o:**
- pthread_exit() libera stack e TCB
- pthread_join() no main espera pela conclus√£o

No meu caso, com 4 cores:
- Threads 1 e 2 podem executar em paralelo real (cores diferentes)
- Thread 3 compartilha CPU com outra, alternando contexto

### 4. Qual seria o impacto de aumentar o n√∫mero de threads?

Aumentar o n√∫mero de threads teria um impacto n√£o-linear:

**Com 3-4 Threads (Encontrei no Codespace):**
- ‚úÖ Bom: Distribui√ß√£o entre 4 cores
- ‚úÖ Bom: Minimizado context-switching
- ‚úÖ Bom: Cache locality adequada

**Com ~50-100 Threads:**
- ‚ö†Ô∏è Overhead significativo: Cada context switch custa ~1-10¬µs
- ‚ö†Ô∏è Conten√ß√£o de mem√≥ria: Cada thread consome ~8MB
- ‚ö†Ô∏è Thrashing de cache L1/L2

**Com 1000+ Threads:**
- ‚ùå P√©ssimo: Overhead domina computa√ß√£o √∫til
- ‚ùå P√©ssimo: Sistema passa mais tempo em context-switching que c√°lculo

**Lei de Amdahl:**
A melhoria m√°xima √© limitada pela por√ß√£o n√£o-paraleliz√°vel. Se 20% do c√≥digo √© serial, speedup m√°ximo = 1/(0.2 + 0.8/N). Para N=4 cores, speedup m√°ximo ‚âà 2.2x.

No caso espec√≠fico desta atividade:
- Adicionar threads CPU extras dividiria o tempo entre mais threads
- Cada uma ficaria mais lenta (menos CPU cache)
- Benef√≠cio diminuiria com overhead

### 5. O que aconteceria se execut√°ssemos as mesmas opera√ß√µes sequencialmente?

Se execut√°ssemos sequencialmente (uma fun√ß√£o ap√≥s outra):

**C√≥digo Sequencial (Pseudoc√≥digo):**
```
tempo_inicio = clock()
funcao_cpu()      // Aguarda 3.47s
funcao_io()       // Aguarda 0.12s (depois que CPU termina)
funcao_mista()    // Aguarda 0.58s (depois que I/O termina)
tempo_fim = clock()
tempo_total = 3.47 + 0.12 + 0.58 = 4.17 segundos
```

**Com Threads (Paralelo):**
```
tempo_inicio = clock()
thread_cpu()       // 3.47s
thread_io()        // 0.12s (executa durante CPU)
thread_mista()     // 0.58s (executa durante CPU)
// pthread_join aguarda a mais lenta
tempo_fim = clock()
tempo_total = max(3.47, 0.12, 0.58) = 3.47 segundos
```

**Compara√ß√£o:**
- **Sequencial:** 4.17 segundos
- **Paralelo:** 3.47 segundos
- **Ganho:** (4.17 - 3.47) / 4.17 = 16.8% mais r√°pido com threads

**Por que o ganho n√£o √© maior (n√£o √© 4.17 / 3.47 = 1.2x)?**

Porque 16.8% √© o benef√≠cio relativo. Mais especificamente:
- I/O e Mista executam enquanto CPU roda: economizamos 0.70s
- Essa economia √© 16.8% do tempo total sequencial

Em aplica√ß√µes I/O-heavy (como web servers), o ganho √© muito maior. Neste programa, CPU domina o tempo total, limitando o speedup.

---

## Experimentos Adicionais (Opcional)

---

## Experimentos Adicionais (Opcional)

### Modifica√ß√£o 1: Aumentar NUM_ITERACOES

**Altera√ß√£o realizada:** Mudei NUM_ITERACOES de 1000000 para 5000000 (5x maior) na linha 20 de atividade_threads.c

**Resultado observado:**
- Tempo da Thread CPU: 17.35 segundos (vs. 3.47 segundos anterior)
- Tiempo total do programa: ~17 segundos (vs. ~3 segundos anterior)
- Soma dos primos: 187752010115 (n√∫mero maior, como esperado)

**Conclus√£o:** 
Aumentar o tamanho da itera√ß√£o em 5x resultou em aumento do tempo de execu√ß√£o tamb√©m pr√≥ximo a 5x (5.0x exatamente: 17.35 / 3.47). Isso confirma a natureza linear do algoritmo de c√°lculo de primos implementado. A rela√ß√£o O(n) permite prever o tempo com precis√£o. Com essa modifica√ß√£o, a diferen√ßa temporal entre as threads ficou ainda mais pronunciada: Thread I/O (~0.12s) e Mista (~0.58s) terminaram praticamente instantaneamente em compara√ß√£o com a CPU (~17s).

Este experimento demonstra a import√¢ncia de otimizar algoritmos com alta complexidade, pois pequenas mudan√ßas no tamanho da entrada resultam em impacto exponencial no tempo.

---

## Conceitos Aprendidos

Lista dos principais conceitos de sistemas operacionais que compreendi melhor com esta atividade:

1. **Concorr√™ncia vs. Paralelismo** - Threads rodam concorrentemente (dividem CPU) ou paralelamente (m√∫ltiplos cores executam realmente simult√¢neo)

2. **CPU-bound vs. I/O-bound** - Opera√ß√µes intensivas de CPU levam tempos diferentes que opera√ß√µes de entrada/sa√≠da

3. **Escalonamento Preemtivo** - SO interrompe threads para distribuir tempo de CPU equitativamente

4. **Context Switching** - Custo de mudar de uma thread para outra (salvar/restaurar estado)

5. **Biblioteca POSIX Threads (pthread)** - Como criar (pthread_create), sincronizar (pthread_join) e terminar threads (pthread_exit)

6. **Tempo Total em Execu√ß√£o Paralela** - max(tempos_threads), n√£o a soma, quando executam em paralelo real

7. **Non-determinism do Escalonamento** - Mesma aplica√ß√£o pode ter execu√ß√µes com tempos e ordens diferentes

8. **Carga do Sistema e Variabilidade** - Outros processos, cache, estado da mem√≥ria afetam tempos de execu√ß√£o

9. **Compila√ß√£o com FLAGS especiais** - Necessidade de -pthread para linkar biblioteca correta

10. **Race Conditions vs. Sincroniza√ß√£o** - Neste programa, threads n√£o compartilham estado (seguro), mas em geral seria necess√°rio sincroniza√ß√£o

---

## Dificuldades Encontradas

Durante a atividade, encontrei as seguintes considera√ß√µes:

1. **Interpreta√ß√£o de dados de tempo** - Inicialmente confundi "Tempo de CPU" (retornado por clock()) com "Tempo Real" (retornado por time()). Clock() mede tempo de processador, que √© diferente de tempo calend√°rio. Para opera√ß√µes I/O, clock() n√£o inclui tempo de espera no disco.

2. **Ordem de conclus√£o n√£o sempre √≥bvia** - Teve que ser cuidadoso para notar qual thread imprimiu sua mensagem "conclu√≠da" primeiro, pois as mensagens podem aparecer intercaladas.

3. **Variabilidade entre execu√ß√µes** - A primeira execu√ß√£o teve tempos ligeiramente diferentes da segunda, o que inicialmente pareceu um erro, mas √© comportamento esperado de threads.

4. **Compreens√£o de Escalonamento** - Entender exatamente como o SO escolhe qual thread rodar em cada momento foi desafiador, pois √© n√£o-determin√≠stico.

**Resolu√ß√µes:**
- Ler documenta√ß√£o de clock() vs. time() em Linux
- Executar m√∫ltiplas vezes para confirmar padr√µes
- Pesquisar sobre CFS (Completely Fair Scheduler) do Linux
- Usar ferramentas como strace/perf para observar system calls

---

## Coment√°rios Finais

Esta atividade foi extremamente valiosa para consolidar conhecimentos te√≥ricos sobre concorr√™ncia e threads. Ver na pr√°tica como:
- Diferentes tipos de opera√ß√£o (CPU vs. I/O) t√™m caracter√≠sticas distintas
- Execu√ß√£o paralela √© mais eficiente que sequencial
- O SO gerencia recursos de forma sofisticada

O programa √© educacional, mas realista. Aplica√ß√µes do mundo real (servidores web, processamento de imagens, sistemas multim√≠dia) usam threads de formas semelhantes.

Uma extens√£o interessante seria:
- Adicionar sincroniza√ß√£o com mutexes
- Implementar um pool de threads
- Medir cache hits/misses com perf
- Comparar com processos vs. threads

Avalia√ß√£o geral da atividade: **Excelente para iniciantes em Sistemas Operacionais** üéì

---

**Data de Conclus√£o:** 12/02/2026
**Assinatura:** Aluno de Sistemas Operacionais
